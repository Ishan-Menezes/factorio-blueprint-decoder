#!/usr/bin/python3

import argparse
import sys
import struct
import json
import time
from enum import Enum


PERL_LEGACY_FORMAT = True


################################################################
#
# utilities

def debug(*args):
    if opt.d:
        print(*args, file=sys.stderr, flush=True)

def verbose(*args):
    if opt.v or opt.d:
        print(*args, file=sys.stderr, flush=True)


class ParseError(Exception):
    pass


################################################################
#
# Index

class Index:

    # types (distinct number ranges)
    # `value` is the prototype-class (except "entity"). In BP exports the wording is just "virtual".
    class Type(Enum):
        ITEM = "item"
        FLUID = "fluid"
        VSIGNAL = "virtual-signal"
        TILE = "tile"
        ENTITY = "entity"
        RECIPE = "recipe"

    ITEM = Type.ITEM
    FLUID = Type.FLUID
    VSIGNAL = Type.VSIGNAL
    TILE = Type.TILE
    ENTITY = Type.ENTITY
    RECIPE = Type.RECIPE

    _type_mapping = {
        # item
        "ammo": ITEM,
        "armor": ITEM,
        "blueprint": ITEM,
        "blueprint-book": ITEM,
        "capsule": ITEM,
        "deconstruction-item": ITEM,
        "gun": ITEM,
        "item": ITEM,
        "item-with-entity-data": ITEM,
        "module": ITEM,
        "spidertron-remote": ITEM,
        "rail-planner": ITEM,
        "repair-tool": ITEM,
        "tool": ITEM,
        "upgrade-item": ITEM,
        # fluid
        "fluid": FLUID,
        # virtual-signal
        "virtual-signal": VSIGNAL,
        # entity
        "accumulator": ENTITY,
        "ammo-turret": ENTITY,
        "arithmetic-combinator": ENTITY,
        "artillery-turret": ENTITY,
        "artillery-wagon": ENTITY,
        "assembling-machine": ENTITY,
        "beacon": ENTITY,
        "boiler": ENTITY,
        "cargo-wagon": ENTITY,
        "cliff": ENTITY,
        "constant-combinator": ENTITY,
        "container": ENTITY,
        "curved-rail": ENTITY,
        "decider-combinator": ENTITY,
        "electric-pole": ENTITY,
        "electric-turret": ENTITY,
        "entity-ghost": ENTITY,
        "fish": ENTITY,
        "fluid-turret": ENTITY,
        "fluid-wagon": ENTITY,
        "furnace": ENTITY,
        "gate": ENTITY,
        "generator": ENTITY,
        "heat-pipe": ENTITY,
        "infinity-container": ENTITY,
        "inserter": ENTITY,
        "item-entity": ENTITY,
        "item-request-proxy": ENTITY,
        "lab": ENTITY,
        "lamp": ENTITY,
        "land-mine": ENTITY,
        "locomotive": ENTITY,
        "logistic-container": ENTITY,
        "mining-drill": ENTITY,
        "offshore-pump": ENTITY,
        "pipe": ENTITY,
        "pipe-to-ground": ENTITY,
        "power-switch": ENTITY,
        "programmable-speaker": ENTITY,
        "pump": ENTITY,
        "radar": ENTITY,
        "rail-chain-signal": ENTITY,
        "rail-signal": ENTITY,
        "reactor": ENTITY,
        "roboport": ENTITY,
        "rocket-silo": ENTITY,
        "simple-entity": ENTITY,
        "solar-panel": ENTITY,
        "splitter": ENTITY,
        "storage-tank": ENTITY,
        "straight-rail": ENTITY,
        "tile-ghost": ENTITY,
        "train-stop": ENTITY,
        "transport-belt": ENTITY,
        "tree": ENTITY,
        "underground-belt": ENTITY,
        "wall": ENTITY,
        # tile
        "tile": TILE,
        # recipe
        "recipe": RECIPE,
    }

    class Entry:
        def __init__(self, id: int, type, prototype: str, name: str):
            self.id = id
            self.type = type
            self.prototype = prototype
            self.name = name

    def __init__(self):
        self._data = {
            self.ITEM: {},
            self.FLUID: {},
            self.VSIGNAL: {},
            self.TILE: {},
            self.ENTITY: {},
            self.RECIPE: {},
        }

    def add(self, id: int, prototype: str, name: str) -> Entry:
        if id == 0x00:
            raise ValueError("ID 0 is not allowed")
        type = self._type_mapping[prototype]
        bucket = self._data[type]
        if id in bucket:
            raise ValueError(f"ID {id} ({id:#x}) is already used for '{bucket[id]['name']}'")
        entry = bucket[id] = Index.Entry(id, type, prototype, name)
        return entry

    def get(self, type: Type, id: int) -> Entry:
        return self._data[type][id]


################################################################
#
# primitives

class PrimitiveStream:

    def __init__(self, f):
        self._f = f

    def _read(self, format):
        return struct.unpack(
            format,
            self._f.read(struct.calcsize(format)))[0]

    def tell(self):
        return self._f.tell()

    def bool(self):
        data = self.u8()
        if data != 0x00 and data != 0x01:
            raise ParseError(f"invalid boolean value {data:#04x} at position {self.tell()-1:#06x}")
        return data == 0x01

    def s8(self):
        return self._read("<b")

    def u8(self):
        return self._read("<B")

    def s16(self):
        return self._read("<h")

    def u16(self):
        return self._read("<H")

    def s32(self):
        return self._read("<i")

    def u32(self):
        return self._read("<I")

    # see https://en.wikipedia.org/wiki/Single-precision_floating-point_format#Single-precision_examples
    # for remarkable examples like "0x3f80_0000" for "1"
    def f32(self):
        return self._read("<f")

    # see https://en.wikipedia.org/wiki/Double-precision_floating-point_format#Double-precision_examples
    # for remarkable examples like "0x3ff0_0000_0000_0000" for "1"
    def f64(self):
        return self._read("<d")

    def count(self):
        length = self.u8()
        if length == 0xff:
            return self.u32()
        else:
            return length

    def count8(self):
        data = self.u8()
        if data == 0xff:
            file_position = self.tell()
            raise ParseError("unexpected flexible length 0xff @{file_position:#x}")
        return data

    def count16(self):
        return self.u16()

    def count32(self):
        return self.u32()

    def string(self):
        length = self.count()
        return self._f.read(length).decode("utf-8")

    def dump_trailing_data(self):
        def to_hex(s: str):
            return " ".join([f'{b:02x}' for b in s])

        position, data = self._f.tell(), self._f.read(16)
        if data:
            debug("trailing data:")
            while data:
                debug(f"{position:06x}", to_hex(data))
                position, data = self._f.tell(), self._f.read(16)


################################################################
#
# stream helpers

def read_entry(stream, index: Index, type: Index.Type) -> Index.Entry:
    if type == Index.TILE:
        id = stream.u8()
    else:
        id = stream.u16()

    if id:
        # FIXME: catch KeyError and supply a better error message
        return index.get(type, id)
    else:
        return None


def read_name(stream, index: Index, type: Index.Type) -> Index.Entry:
    entry = read_entry(stream, index, type)
    if entry:
        return entry.name
    else:
        return None


def read_signal_new(stream, index: Index):
    index_type = read_mapped8(stream, (Index.ITEM, Index.FLUID, Index.VSIGNAL))
    entry = read_entry(stream, index, index_type)
    if not entry:
        return None
    return {
        "type": {Index.ITEM: "item", Index.FLUID: "fluid", Index.VSIGNAL: "virtual"}[index_type],
        "name": entry.name
    }


def read_signal_compat(stream, index: Index):
    index_type = read_mapped8(stream, (Index.ITEM, Index.FLUID, Index.VSIGNAL))
    name = read_name(stream, index, index_type)
    return {
        "type": {Index.ITEM: "item", Index.FLUID: "fluid", Index.VSIGNAL: "virtual"}[index_type],
        "name": name
    }

def read_signal(stream, index: Index):
    # FIXME: The Perl version actually returns an "empty" signal for id 0x00.
    #       The Python version returns None. The export seems to omit these
    #       signals, so Python won't go back but wait.
    if PERL_LEGACY_FORMAT:
        return read_signal_compat(stream, index)
    else:
        return read_signal_new(stream, index)


# circuit condition, logistic condition, train schedules
def read_condition(stream, index: Index):
    # same order in drop-down
    comparator = read_mapped8(stream, (">", "<", "=", "≥", "≤", "≠"))

    first_signal = read_signal(stream, index)
    second_signal = read_signal(stream, index)
    constant = stream.s32()
    use_constant = stream.bool()

    # hide "default" condition
    if not first_signal and not second_signal and comparator == "<" and not constant:
        return None

    condition = {}
    condition["first_signal"] = first_signal
    condition["comparator"] = comparator
    # The export does not output data if it is hidden in the UI.
    if use_constant:
        condition["constant"] = constant
    else:
        condition["second_signal"] = second_signal

    return condition


def read_mapped8(stream, args):
    index = stream.u8()
    if index in range(len(args)):
        return args[index]
    else:
        position = stream.tell() - 1
        raise ParseError(f"unexpected value {index} at position {position}: only 0..{len(args)-1} expected")


def read_unknown(stream: PrimitiveStream, *expected_bytes):
    if not expected_bytes:
        expected_bytes = 0x00,

    for expected in expected_bytes:
        actual = stream.u8()
        if actual != expected:
            position = stream.tell()
            raise ParseError(f"expected {expected:#04x} but got {actual:#04x} at position {position} ({position:#x})")


################################################################
#
# entity parts (ep_*)


def ep_entity_ids(stream, index, entity):
    flags = stream.u8()
    # 0x10	-- has entity id (default=0)
    if flags | 0x10 != 0x10:
        raise ParseError(f"unexpected flags {flags:#04x} at position {stream.tell()-1:#x}")

    if flags & 0x10:
        read_unknown(stream, 0x01)
        entity_id = stream.u32()
        entity["entity_id"] = entity_id
        debug(f"\tentity-id: {entity_id}")
        # TODO: in export "entity_"number" but "entity_id" in references.
        # Also: EACH entity in the export has the number and entities are
        # numbered 1..N.


def ep_bar(stream, index, entity):
    # "Warehousing Mod" writes 2000 stacks but the UI reports 1800.
    bar = stream.u16()
    # The export format suppresses the default values. But these
    # are - in general - unknown to me beyond the vanilla chests.
    bar_defaults = {
        # container
        "wooden-chest" : 0x10,
        "iron-chest"   : 0x20,
        "steel-chest"  : 0x30,
        # logistic-container
        "logistic-chest-active-provider"	: 0x30,
        "logistic-chest-passive-provider"	: 0x30,
        "logistic-chest-storage"	: 0x30,
        "logistic-chest-requester"	: 0x30,
        "logistic-chest-buffer"		: 0x30,
        # cheat mode
        "infinity-chest" : 0x30,
        # trains
        "cargo-wagon"	 : 0x28,
    }
    default_bar = bar_defaults.get(entity["name"], None)
    if not default_bar or default_bar != bar:
        entity["bar"] = bar


# maybe helpfull: https://wiki.factorio.com/Types/Direction
def ep_direction(stream, index, entity):
    direction = stream.u8()
    if direction:
        entity["direction"] = direction


def ep_circuit_connections(stream, index, entity, own_circuit_id="1"):
    connections = {}

    # How many "colors"?
    # https://lua-api.factorio.com/latest/defines.html#defines.wire_type
    for color in ("red", "green"):
        peers = []
        peer_count = stream.count8()
        for p in range(peer_count):
            entity_id = stream.u32()
            circuit_id = stream.u8()
            peers.append({
                "entity_id": entity_id,
                # TODO: skip "circuit_id" for "simple" circuits
                "circuit_id": circuit_id
            })
            read_unknown(stream, 0xff)
        if peers:
            connections[color] = peers

    # maybe helpfull: https://lua-api.factorio.com/latest/defines.html#defines.circuit_connector_id

    if connections:
        if "connections" not in entity:
            entity["connections"] = {}
        entity["connections"][str(own_circuit_id)] = connections

    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)


def ep_circuit_condition(stream, index, entity):
    circuit_condition = read_condition(stream, index)
    if circuit_condition:
        control_behavior = entity.setdefault("control_behavior", {})
        control_behavior["circuit_condition"] = circuit_condition


def ep_logistic_condition(stream, index, entity):
    logistic_condition = read_condition(stream, index)
    if logistic_condition:
        control_behavior = entity.setdefault("control_behavior", {})
        control_behavior["logistic_condition"] = logistic_condition

    logistic_connected = stream.bool()
    if logistic_connected:
        control_behavior = entity.setdefault("control_behavior", {})
        control_behavior["connect_to_logistic_network"] = True
    else:
        if "control_behavior" in entity:
            entity["control_behavior"].pop("logistic_condition", None)

def ep_filters(stream, index, entity):
    # Even without filters the count is > 0 for filter-inserters.
    filter_count = stream.u8()
    if not filter_count:
        return

    filters = []
    for f in range(filter_count):
        filter_name = read_name(stream, index, Index.ITEM)
        filters.append(filter_name)
    entity["filters"] = filters
    # TODO: The export file suppresses an empty list (or a list with only None entries).
    # TODO: The export also uses a map, not an array, hence the items have an additional index field.


def ep_items(stream, index, entity):

    # Interesting point: Modules are not a simple list like icons.
    # Instead the modules are first sorted and then grouped by type.
    # So building an assembler with modules Eff1, Sp1, Eff1, Sp1 the blueprint
    # only contains the data "Sp1: 2, Eff:2". So some details are omitted.

    items = {}
    item_count = stream.u32()
    for i in range(item_count):
        item_name = read_name(stream, index, Index.ITEM)
        item_count = stream.u32()
        items[item_name] = item_count
    if items:
        entity["items"] = items


def ep_color(stream, index, entity):
    use_colors = stream.bool()
    if use_colors:
        entity["colors"] = {
            "r": stream.f32(),
            "g": stream.f32(),
            "b": stream.f32(),
            "a": stream.f32()
        }


################################################################
#
# entity handlers (eh_*)

def eh_container(stream, index, entity):

    # entity ids
    ep_entity_ids(stream, index, entity)

    # restriction aka. "bar"
    ep_bar(stream, index, entity)

    # circuit connections
    has_circuit_connections = stream.bool()
    if has_circuit_connections:
        ep_circuit_connections(stream, index, entity)

    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00)


def eh_logistic_container(stream, index, entity):

    # entity ids
    ep_entity_ids(stream, index, entity)

    # restriction aka. "bar"
    ep_bar(stream, index, entity)

    read_unknown(stream, 0x00)
    read_unknown(stream, 0x01)

    logistic_mode = stream.u8()  # not used in export
    if not 0 <= logistic_mode <= 5:
        raise ParseError(f"unknown logistic mode {logistic_mode}")

    read_unknown(stream, 0x03)

    request_filters = []
    filter_count = stream.count8()
    for f in range(filter_count):
        item_name = read_name(stream, index, Index.ITEM)
        item_count = stream.u32()
        read_unknown(stream)
        if item_name:
            request_filters.append({
                "name": item_name,
                "count": item_count
            })
        else:
            request_filters.append(None)
    if filter_count > 0:
        # Strange: First occurance of the pattern that the list size affects
        # the presence/absence of data after the list.
        request_from_buffers = stream.bool()
        if request_from_buffers:
            entity["request_from_buffers"] = True

    # TODO: export compresses the filter list
    if request_filters:
        entity["request_filters"] = request_filters

    read_unknown(stream, 0x00, 0x00)

    # circuit connections
    has_circuit_connections = stream.bool()
    if has_circuit_connections:
        ep_circuit_connections(stream, index, entity)
        # strange: is this some padding?
        read_unknown(stream)

    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00)


def eh_infinity_container(stream, index, entity):

    # entity ids
    ep_entity_ids(stream, index, entity)

    # restriction aka. "bar"
    ep_bar(stream, index, entity)

    read_unknown(stream, 0x00, 0x00)

    # circuit connections
    has_circuit_connections = stream.bool()
    if has_circuit_connections:
        ep_circuit_connections(stream, index, entity)
        # strange: is this some padding?
        read_unknown(stream)

    # infinity settings
    entity["infinity_settings"] = {}

    filters = []
    filter_count = stream.count8()
    for f in range(filter_count):
        item_name = read_name(stream, index, Index.ITEM)
        item_count = stream.u32()
        mode = read_mapped8(stream, ("at-least", "at-most", "exactly"))
        filters.append({
            "name": item_name,
            "count": item_count,
            "mode": mode
        })
    if filters:
        entity["infinity_settings"]["filters"] = filters

    remove_unfiltered_items = stream.bool()
    entity["infinity_settings"]["remove_unfiltered_items"] = remove_unfiltered_items

    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00)


def eh_inserter(stream, index, entity):
    # entity ids
    ep_entity_ids(stream, index, entity)

    # 0x01 -- override_stack_size
    # 0x02 -- filter_mode: 0=blacklist, 1(default)=whitelist
    # 0x04 -- TODO - unknown - default=1(?)
    # others: TODO - unknown - default=0(?)
    flags = stream.u8()
    if flags | 0x03 != 0x07:
        raise ParseError(f"unexpected flag {flags:#04x} at position {stream.tell()-1:#x}")

    # direction
    ep_direction(stream, index, entity)

    # override stack size
    if flags & 0x01:
        entity["override_stack_size"] = stream.u8()

    # circuit network connections
    has_circuit_connections = stream.bool()
    if has_circuit_connections:
        # connections
        ep_circuit_connections(stream, index, entity)

        # circuit condition & logistic condition
        ep_circuit_condition(stream, index, entity)
        ep_logistic_condition(stream, index, entity)

        read_unknown(stream, 0x00, 0x00)

        # mode of operation

        control_behavior = entity.setdefault("control_behavior", {})

        # maybe helpfull: https://lua-api.factorio.com/latest/defines.html#defines.control_behavior
        mode_of_operation = stream.u8()
        if mode_of_operation:
            control_behavior["circuit_mode_of_operation"] = mode_of_operation

        read_hand_flag = stream.bool()
        read_hand_mode = stream.bool() # not a bool but only 0/1 allowed
        if read_hand_flag:
            control_behavior["circuit_read_hand_contents"] = True
        if read_hand_mode:
            control_behavior["circuit_hand_read_mode"] = 1

        set_stack_size = stream.bool()
        if set_stack_size:
            control_behavior["circuit_set_stack_size"] = True
        stack_control_input_signal = read_signal(stream, index)
        if stack_control_input_signal:
            control_behavior["stack_control_input_signal"] = stack_control_input_signal

        # End of "mode of operation"

    # item filters
    ep_filters(stream, index, entity)

    if not flags & 0x02:
        entity["filter_mode"] = "blacklist"

    # pickup/drop position
    is_miniloader = stream.bool()
    if is_miniloader:
        # examples: miniloader mod
        entity["drop_position"] = {
            "x": stream.f64(),
            "y": stream.f64()
        }
        entity["pickup_position"] = {
            "x": stream.f64(),
            "y": stream.f64()
        }

    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00)


def eh_pipe(stream, index, entity):
    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)


def eh_pipe_to_ground(stream, index, entity):
    read_unknown(stream)
    ep_direction(stream, index, entity)
    read_unknown(stream, 0x00, 0x00, 0x00, 0x00, 0x00)


entity_handlers = {
    "container": eh_container,
    "logistic-container": eh_logistic_container,
    "infinity-container": eh_infinity_container,
    "inserter": eh_inserter,
    "pipe": eh_pipe,
    "pipe-to-ground": eh_pipe_to_ground,
}


################################################################
#
# library -- utilities

def parse_version(stream, result):
    version = (
        stream.u16(),
        stream.u16(),
        stream.u16(),
        stream.u16(),
    )
    debug(f"version: {'.'.join(map(str, version))}")
    result["version"] = version


def parse_migrations(stream, result):
    migrations = []
    migration_count = stream.count8()
    if opt.x:
        debug(f"migrations: {migration_count}")
    for m in range(migration_count):
        mod_name = stream.string()
        migration_file = stream.string()
        if opt.x:
            debug(f"    [{m}] mod '{mod_name}', migration '{migration_file}'")
        migrations.append({
            "mod_name": mod_name,
            "migration_file": migration_file
        })
    if opt.x:
        result["migrations"] = migrations


def parse_index(stream, result):
    index = Index()
    index_dict = {}

    prototype_count = stream.count16()
    debug(f"used prototypes: {prototype_count}")
    for p in range(prototype_count):
        prototype_name = stream.string()
        names = index_dict[prototype_name] = {}
        if prototype_name == "tile":    # strange exception
            name_count = stream.count8()
            debug(f"    [{p}] prototype '{prototype_name}' - entries: {name_count}")
            for n in range(name_count):
                name_id = stream.u8()
                name = stream.string()
                debug(f"        [{n}] {name_id:02x} '{name}'")
                names[name_id] = name
                index.add(name_id, prototype_name, name)
        else:
            name_count = stream.count16()
            debug(f"    [{p}] prototype '{prototype_name}' - entries: {name_count}")
            for n in range(name_count):
                name_id = stream.u16()
                name = stream.string()
                debug(f"        [{n}] {name_id:04x} '{name}'")
                names[name_id] = name
                index.add(name_id, prototype_name, name)

    if index_dict and opt.x:
        result["index"] = index_dict

    return index


object_prototypes = (
    "blueprint",
    "blueprint-book",
    "deconstruction-item",
    "upgrade-item",
)

def parse_library_objects(stream, index, result):

    object_count = stream.count32()
    verbose(f"\nlibrary objects: {object_count}")
    objects = []
    for o in range(object_count):
        is_used = stream.bool()
        if is_used:
            verbose(f"\n[{o}] library slot: used")

            # Interesting: Here is a rare redundancy.
            object_prototype_by_byte = read_mapped8(stream, object_prototypes)

            # See _generation_counter_ in parse_blueprint_library for details.
            generation = stream.u32()

            entry = read_entry(stream, index, Index.ITEM)
            if entry.prototype != object_prototype_by_byte:
                raise ParseError(
                    f"mismatch between content-type '{object_prototype_by_byte}'"
                    f" and actual content item {entry.prototype}")

            handler = object_handlers.get(entry.prototype, None)
            if not handler:
                raise ParseError(f"no handler for {entry.prototype}/{entry.name} ({entry.id:#x})")

            handler_result = handler(stream, index)
            handler_result["_generation_"] = generation
            objects.append(handler_result)
        else:
            verbose(f"\n[{o}] library slot: free")
            objects .append(None)

    result["blueprints"] = objects


def parse_icons(stream, index, result):
    icons = []
    icon_count = stream.count8()
    if not icon_count:
        return
    debug(f"icons: {icon_count}")
    for i in range(icon_count):
        icon = read_signal(stream, index)
        if icon:
            debug(f"    [{i}] '{icon['type']}' / '{icon['name']}'")
            icons.append(icon)
        else:
            debug(f"    [{i}] (none)")
            icons.append(None)
    if icons:
        result["icons"] = icons


def parse_snap_to_grid(stream, result):
    snap_to_grid = stream.bool()
    if snap_to_grid:
        x = stream.u32()
        y = stream.u32()
        result["snap-to-grid"] = {
            "x": x,
            "y": y
        }

        absolute_snapping = stream.bool()
        if absolute_snapping:
            result["absolute-snapping"] = absolute_snapping

def parse_entities(stream, index, result):
    entities = result["entities"] = []

    entity_count = stream.count32()
    debug(f"entities: {entity_count}")
    for e in range(entity_count):
        file_position = stream.tell()

        # type/name
        entry = read_entry(stream, index, Index.ENTITY)

        # position

        # maybe helpfull: https://wiki.factorio.com/Data_types
        # maybe helpfull: https://wiki.factorio.com/Types/Position
        offset_x = stream.s16()     # lookahead
        if offset_x == 0x7fff:
            position = {
                "x": stream.s32() / 256,
                "y": stream.s32() / 256
            }
        else:
            offset_y = stream.s16()
            if entities:
                last_position = entities[-1]["position"]
                position = {
                    "x": last_position["x"] + offset_x / 256,
                    "y": last_position["y"] + offset_y / 256
                }
            else:
                position = {
                    "x": offset_x / 256,
                    "y": offset_y / 256
                }

        # debug output
        debug(f"    [{len(entities)}] @{file_position:#x} - "
            f"x: {position['x']}, y: {position['y']}, "
            f"'{entry.prototype}/{entry.name}'")

        # attach entity
        entity = {
            "name": entry.name,
            "position": position,
        }
        entities.append(entity)

        # Strange: What is this?
        read_unknown(stream, 0x20)

        # parse entity details
        handler = entity_handlers.get(entry.prototype, None)
        if not handler:
            raise ParseError(f"no entity handler for {entry.prototype}/{entry.name} ({entry.id:#x})")
        handler(stream, index, entity)
    
    if not entities:
        del result["entities"]


def parse_schedules(stream, index, result):
    schedules_count = stream.count8()
    schedules = []
    for sc in range(schedules_count):
        schedule = {
            "schedule": []
        }

        locomotives = schedule["locomotives"] = []
        locomotive_count = stream.count8()
        for lo in range(locomotive_count):
            locomotive_id = stream.u32()
            locomotives.append(locomotive_id)

        station_count = stream.count8()
        for st in range(station_count):
            station = {
                "station": stream.string(),
                "wait_conditions": [],
            }

            wait_condition_count = stream.u32()
            for wc in range(wait_condition_count):
                wait_condition = {}

                wait_condition_types = (
                    "time",
                    "full",
                    "empty",
                    "item_count",
                    "circuit",
                    "inactivity",
                    None, # what is type 6?
                    "fluid_count",
                    "passenger_present",
                    "passenger_not_present",
                )
                wait_condition["type"] = read_mapped8(stream, wait_condition_types)

                wait_condition["compare_type"] = read_mapped8(stream, ("and", "or"))

                ticks = stream.u16()
                if ticks:
                    # TODO: export features "ticks: 0" for "time" and "inactivity"
                    wait_condition["ticks"] = ticks

                read_unknown(stream, 0x00, 0x00)

                condition = read_condition(stream, index)
                if condition:
                    wait_condition["condition"] = condition

                station["wait_conditions"].append(wait_condition)

            read_unknown(stream)

            schedule["schedule"].append(station)

        schedules.append(schedule)

    if schedules:
        result["schedules"] = schedules


def parse_tiles(stream, index, result):
    tiles = []
    tile_count = stream.count32()
    debug(f"tiles: {tile_count}")
    for t in range(tile_count):
        tiles.append({
            "position": {
                "x": stream.s32(),
                "y": stream.s32()
            },
            "name": read_name(stream, index, Index.TILE)
        })

    if tiles:
        result["tiles"] = tiles


################################################################
#
# library -- primary objects

def parse_blueprint_library(stream: PrimitiveStream):
    result = {}

    parse_version(stream, result)

    read_unknown(stream)

    parse_migrations(stream, result)

    global_index = parse_index(stream, result)

    read_unknown(stream, 0x00, 0x00)

    # Adding a blueprint to the library increments the counter, deleting and moving does not.
    # When a new blueprint is added to the library this global counter is copied to the new
    # blueprint and incremened after that. This happens for each new blueprint, not per save.
    generation_counter = stream.u32()
    debug(f"generation counter: {generation_counter} ({generation_counter:#x})")
    result["_generation_counter_"] = generation_counter

    # unix timestamp
    timestamp = stream.u32()    # u32/s32?
    timestring = time.strftime("%FT%T%z", time.localtime(timestamp)) # localtime/gmtime?
    # FIXME: use datetime.fromtimestamp(timestamp, timezone.utc) or something like that
    debug(f"timestamp: {timestring}")
    result["_save_timestamp_"] = timestring

    read_unknown(stream, 0x01)

    parse_library_objects(stream, global_index, result)

    return result


def parse_blueprint(stream: PrimitiveStream, index):
    result = {
        "item": "blueprint",
    }

    file_position = stream.tell()

    label = result["label"] = stream.string()
    verbose(f"blueprint '{label}' (@{file_position:#x})")

    read_unknown(stream, 0x00, 0x00)

    # might be "flexible size" marker for $content_size. But since the
    # "migrations" section for 1.0.0.0 is already 347 bytes there is no
    # way to check that.
    read_unknown(stream, 0xff)
    # Interesting: A rare redundancy. Could be used to fast skimming
    # the library. Reasons: a) Speed, b) unparsable content due to mods/versions.
    content_size = stream.u32()
    content_start = stream.tell()

    parse_version(stream, result)

    read_unknown(stream)

    parse_migrations(stream, result)

    result["description"] = stream.string()

    parse_snap_to_grid(stream, result)

    parse_entities(stream, index, result)

    parse_schedules(stream, index, result)

    parse_tiles(stream, index, result)

    read_unknown(stream)

    parse_icons(stream, index, result)

    content_end = stream.tell()
    parsed_size = content_end - content_start
    if parsed_size != content_size:
        raise AssertionError(f"mismatch between declared blueprint size ({content_size})"
            f" and parsed size ({parsed_size})")

    return result


def parse_blueprint_book(stream: PrimitiveStream, index):
    result = {
        "item": "blueprint-book",
    }

    file_position = stream.tell()

    label = result["label"] = stream.string()
    verbose(f"blueprint-book '{label}' (@{file_position:#x})")

    result["description"] = stream.string()

    read_unknown(stream)

    parse_icons(stream, index, result)

    parse_library_objects(stream, index, result)

    active_index = stream.u8()
    if active_index:
        result["active_index"] = active_index

    read_unknown(stream)

    verbose(f"end of book '{label}' (@{stream.tell():#x})")

    return result


def parse_deconstruction_item(stream: PrimitiveStream, index):
    def read_filter(section_name, type):
        filters = []
        filter_count = stream.u8()
        debug(f"{section_name.replace('_', '-')}: {filter_count}")
        for e in range(filter_count):
            name = read_name(stream, index, type)
            filters.append(name)
        result["settings"][section_name] = filters

    result = {
        "item": "deconstruction-planner",
        "settings": {},
    }

    file_position = stream.tell()

    result["label"] = stream.string()
    result["settings"]["description"] = stream.string()

    verbose(f"deconstruction-item '{result['label']}' (@{file_position:#x})")

    read_unknown(stream)

    parse_icons(stream, index, result)

    entity_filter_mode = stream.u8()
    if entity_filter_mode:
        result["settings"]["entity_filter_mode"] = entity_filter_mode

    read_unknown(stream)

    read_filter("entity_filters", Index.ENTITY)

    trees_and_rocks_only = stream.bool()
    if trees_and_rocks_only:
        result["settings"]["trees_and_rocks_only"] = True

    tile_filter_mode = stream.u8()
    if tile_filter_mode:
        result["settings"]["tile_filter_mode"] = tile_filter_mode

    tile_selection_mode = stream.u8()
    if tile_selection_mode:
        result["settings"]["tile_selection_mode"] = tile_selection_mode

    read_unknown(stream)

    read_filter("tile_filters", Index.TILE)

    return result


def parse_upgrade_item(stream: PrimitiveStream, index):
    result = {
        "item": "upgrade-planner",
        "settings": {}
    }

    file_position = stream.tell()

    result["label"] = stream.string()
    result["settings"]["description"] = stream.string()

    verbose(f"upgrade-item '{result['label']}' (@{file_position:#x})")

    read_unknown(stream)

    parse_icons(stream, index, result)

    read_unknown(stream)

    def reader():
        type = read_mapped8(stream, (Index.ENTITY, Index.ITEM))
        name = read_name(stream, index, type)
        if name:
            return {
                "type": type.value,
                "name": name
            }
        else:
            return None

    mappers = []
    mapper_count = stream.count8()
    for m in range(mapper_count):
        # see read_signal but the types are different
        _from = reader()
        _to = reader()
        if _from or _to:
            mappers.append({
                "from": _from,
                "to": _to
            })
        else:
            mappers.append(None)

    result["settings"]["mappers"] = mappers
    return result


object_handlers = {
    "blueprint": parse_blueprint,
    "blueprint-book": parse_blueprint_book,
    "deconstruction-item": parse_deconstruction_item,
    "upgrade-item": parse_upgrade_item,
}


################################################################
#
# main

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--verbose", action="store_true", dest="v",
        help="verbose output on STDERR")
    parser.add_argument("-d", "--debug", action="store_true", dest="d",
        help="debug output on STDERR")
    parser.add_argument("-x", "--extended", action="store_true", dest="x",
        help="extended output: add voluminous stuff found .dat but not used in .export"
        " Currently:\n - migrations\n - prototype index")
    parser.add_argument("filename", nargs="?", default="blueprint-storage.dat")
    opt = parser.parse_args()

    verbose(f"file: {opt.filename}")
    with open(opt.filename, "rb") as f:
        library = parse_blueprint_library(PrimitiveStream(f))
        print(json.dumps(library, indent=4, sort_keys=True, ensure_ascii=False))
