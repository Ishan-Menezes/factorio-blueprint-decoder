#!/usr/bin/python3

import argparse
import sys
import struct
import json
import time
from enum import Enum


PERL_LEGACY_FORMAT = True


################################################################
#
# utilities

def debug(*args):
    if opt.d:
        print(*args, file=sys.stderr, flush=True)

def verbose(*args):
    if opt.v or opt.d:
        print(*args, file=sys.stderr, flush=True)


class ParseError(Exception):
    pass


################################################################
#
# Index

class Index:

    # types (distinct number ranges)
    # `value` is the prototype-class (except "entity"). In BP exports the wording is just "virtual".
    class Type(Enum):
        ITEM = "item"
        FLUID = "fluid"
        VSIGNAL = "virtual-signal"
        TILE = "tile"
        ENTITY = "entity"
        RECIPE = "recipe"

    ITEM = Type.ITEM
    FLUID = Type.FLUID
    VSIGNAL = Type.VSIGNAL
    TILE = Type.TILE
    ENTITY = Type.ENTITY
    RECIPE = Type.RECIPE

    _type_mapping = {
        # item
        "ammo": ITEM,
        "armor": ITEM,
        "blueprint": ITEM,
        "blueprint-book": ITEM,
        "capsule": ITEM,
        "deconstruction-item": ITEM,
        "gun": ITEM,
        "item": ITEM,
        "item-with-entity-data": ITEM,
        "module": ITEM,
        "spidertron-remote": ITEM,
        "rail-planner": ITEM,
        "repair-tool": ITEM,
        "tool": ITEM,
        "upgrade-item": ITEM,
        # fluid
        "fluid": FLUID,
        # virtual-signal
        "virtual-signal": VSIGNAL,
        # entity
        "accumulator": ENTITY,
        "ammo-turret": ENTITY,
        "arithmetic-combinator": ENTITY,
        "artillery-turret": ENTITY,
        "artillery-wagon": ENTITY,
        "assembling-machine": ENTITY,
        "beacon": ENTITY,
        "boiler": ENTITY,
        "cargo-wagon": ENTITY,
        "cliff": ENTITY,
        "constant-combinator": ENTITY,
        "container": ENTITY,
        "curved-rail": ENTITY,
        "decider-combinator": ENTITY,
        "electric-pole": ENTITY,
        "electric-turret": ENTITY,
        "entity-ghost": ENTITY,
        "fish": ENTITY,
        "fluid-turret": ENTITY,
        "fluid-wagon": ENTITY,
        "furnace": ENTITY,
        "gate": ENTITY,
        "generator": ENTITY,
        "heat-pipe": ENTITY,
        "infinity-container": ENTITY,
        "inserter": ENTITY,
        "item-entity": ENTITY,
        "item-request-proxy": ENTITY,
        "lab": ENTITY,
        "lamp": ENTITY,
        "land-mine": ENTITY,
        "locomotive": ENTITY,
        "logistic-container": ENTITY,
        "mining-drill": ENTITY,
        "offshore-pump": ENTITY,
        "pipe": ENTITY,
        "pipe-to-ground": ENTITY,
        "power-switch": ENTITY,
        "programmable-speaker": ENTITY,
        "pump": ENTITY,
        "radar": ENTITY,
        "rail-chain-signal": ENTITY,
        "rail-signal": ENTITY,
        "reactor": ENTITY,
        "roboport": ENTITY,
        "rocket-silo": ENTITY,
        "simple-entity": ENTITY,
        "solar-panel": ENTITY,
        "splitter": ENTITY,
        "storage-tank": ENTITY,
        "straight-rail": ENTITY,
        "tile-ghost": ENTITY,
        "train-stop": ENTITY,
        "transport-belt": ENTITY,
        "tree": ENTITY,
        "underground-belt": ENTITY,
        "wall": ENTITY,
        # tile
        "tile": TILE,
        # recipe
        "recipe": RECIPE,
    }

    class Entry:
        def __init__(self, id: int, type, prototype: str, name: str):
            self.id = id
            self.type = type
            self.prototype = prototype
            self.name = name

    def __init__(self):
        self._data = {
            self.ITEM: {},
            self.FLUID: {},
            self.VSIGNAL: {},
            self.TILE: {},
            self.ENTITY: {},
            self.RECIPE: {},
        }

    def add(self, id: int, prototype: str, name: str) -> Entry:
        if id == 0x00:
            raise ValueError("ID 0 is not allowed")
        type = self._type_mapping[prototype]
        bucket = self._data[type]
        if id in bucket:
            raise ValueError(f"ID {id} ({id:#x}) is already used for '{bucket[id]['name']}'")
        entry = bucket[id] = Index.Entry(id, type, prototype, name)
        return entry

    def get(self, type: Type, id: int) -> Entry:
        return self._data[type][id]


################################################################
#
# primitives

class PrimitiveStream:

    def __init__(self, f):
        self._f = f

    def _read(self, format):
        return struct.unpack(
            format,
            self._f.read(struct.calcsize(format)))[0]

    def tell(self):
        return self._f.tell()

    def bool(self):
        data = self.u8()
        if data != 0x00 and data != 0x01:
            raise ParseError(f"invalid boolean value {data:#04x} at position {self.tell()-1:#06x}")
        return data == 0x01

    def s8(self):
        return self._read("<b")

    def u8(self):
        return self._read("<B")

    def s16(self):
        return self._read("<h")

    def u16(self):
        return self._read("<H")

    def s32(self):
        return self._read("<i")

    def u32(self):
        return self._read("<I")

    # see https://en.wikipedia.org/wiki/Single-precision_floating-point_format#Single-precision_examples
    # for remarkable examples like "0x3f80_0000" for "1"
    def f32(self):
        return self._read("<f")

    # see https://en.wikipedia.org/wiki/Double-precision_floating-point_format#Double-precision_examples
    # for remarkable examples like "0x3ff0_0000_0000_0000" for "1"
    def f64(self):
        return self._read("<d")

    def count(self):
        length = self.u8()
        if length == 0xff:
            return self.u32()
        else:
            return length

    def count8(self):
        data = self.u8()
        if data == 0xff:
            file_position = self.tell()
            raise ParseError("unexpected flexible length 0xff @{file_position:#x}")
        return data

    def count16(self):
        return self.u16()

    def count32(self):
        return self.u32()

    def string(self):
        length = self.count()
        return self._f.read(length).decode("utf-8")

    def dump_trailing_data(self):
        def to_hex(s: str):
            return " ".join([f'{b:02x}' for b in s])

        position, data = self._f.tell(), self._f.read(16)
        if data:
            debug("trailing data:")
            while data:
                debug(f"{position:06x}", to_hex(data))
                position, data = self._f.tell(), self._f.read(16)


################################################################
#
# stream helpers

def read_entry(stream, index: Index, type: Index.Type) -> Index.Entry:
    if type == Index.TILE:
        id = stream.u8()
    else:
        id = stream.u16()

    if id:
        # FIXME: catch KeyError and supply a better error message
        return index.get(type, id)
    else:
        return None


def read_name(stream, index: Index, type: Index.Type) -> Index.Entry:
    entry = read_entry(stream, index, type)
    if entry:
        return entry.name
    else:
        return None


def read_signal_new(stream, index: Index):
    index_type = read_mapped8(stream, (Index.ITEM, Index.FLUID, Index.VSIGNAL))
    entry = read_entry(stream, index, index_type)
    if not entry:
        return None
    return {
        "type": {Index.ITEM: "item", Index.FLUID: "fluid", Index.VSIGNAL: "virtual"}[index_type],
        "name": entry.name
    }


def read_signal_compat(stream, index: Index):
    index_type = read_mapped8(stream, (Index.ITEM, Index.FLUID, Index.VSIGNAL))
    name = read_name(stream, index, index_type)
    return {
        "type": {Index.ITEM: "item", Index.FLUID: "fluid", Index.VSIGNAL: "virtual"}[index_type],
        "name": name
    }

def read_signal(stream, index: Index):
    # FIXME: The Perl version actually returns an "empty" signal for id 0x00.
    #       The Python version returns None. The export seems to omit these
    #       signals, so Python won't go back but wait.
    if PERL_LEGACY_FORMAT:
        return read_signal_compat(stream, index)
    else:
        return read_signal_new(stream, index)


# circuit condition, logistic condition, train schedules
def read_condition(stream, index: Index):
    # same order in drop-down
    comparator = read_mapped8(stream, (">", "<", "=", "≥", "≤", "≠"))

    first_signal = read_signal(stream, index)
    second_signal = read_signal(stream, index)
    constant = stream.s32()
    use_constant = stream.bool()

    # hide "default" condition
    if not first_signal and not second_signal and comparator == "<" and not constant:
        return None

    condition = {}
    condition["first_signal"] = first_signal
    condition["comparator"] = comparator
    # The export does not output data if it is hidden in the UI.
    if use_constant:
        condition["constant"] = constant
    else:
        condition["second_signal"] = second_signal

    return condition


def read_mapped8(stream, args):
    index = stream.u8()
    if index in range(len(args)):
        return args[index]
    else:
        position = stream.tell() - 1
        raise ParseError(f"unexpected value {index} at position {position}: only 0..{len(args)-1} expected")


def read_unknown(stream: PrimitiveStream, *expected_bytes):
    if not expected_bytes:
        expected_bytes = 0x00,

    for expected in expected_bytes:
        actual = stream.u8()
        if actual != expected:
            position = stream.tell()
            raise ParseError(f"expected {expected:#04x} but got {actual:#04x} at position {position} ({position:#x})")

################################################################
#
# entity handlers (eh_*)


entity_handlers = {
}


################################################################
#
# library -- utilities

def parse_version(stream, result):
    version = (
        stream.u16(),
        stream.u16(),
        stream.u16(),
        stream.u16(),
    )
    debug(f"version: {'.'.join(map(str, version))}")
    result["version"] = version


def parse_migrations(stream, result):
    migrations = []
    migration_count = stream.count8()
    if opt.x:
        debug(f"migrations: {migration_count}")
    for m in range(migration_count):
        mod_name = stream.string()
        migration_file = stream.string()
        if opt.x:
            debug(f"    [{m}] mod '{mod_name}', migration '{migration_file}'")
        migrations.append({
            "mod_name": mod_name,
            "migration_file": migration_file
        })
    if opt.x:
        result["migrations"] = migrations


def parse_index(stream, result):
    index = Index()
    index_dict = {}

    prototype_count = stream.count16()
    debug(f"used prototypes: {prototype_count}")
    for p in range(prototype_count):
        prototype_name = stream.string()
        names = index_dict[prototype_name] = {}
        if prototype_name == "tile":    # strange exception
            name_count = stream.count8()
            debug(f"    [{p}] prototype '{prototype_name}' - entries: {name_count}")
            for n in range(name_count):
                name_id = stream.u8()
                name = stream.string()
                debug(f"        [{n}] {name_id:02x} '{name}'")
                names[name_id] = name
                index.add(name_id, prototype_name, name)
        else:
            name_count = stream.count16()
            debug(f"    [{p}] prototype '{prototype_name}' - entries: {name_count}")
            for n in range(name_count):
                name_id = stream.u16()
                name = stream.string()
                debug(f"        [{n}] {name_id:04x} '{name}'")
                names[name_id] = name
                index.add(name_id, prototype_name, name)

    if index_dict and opt.x:
        result["index"] = index_dict

    return index


object_prototypes = (
    "blueprint",
    "blueprint-book",
    "deconstruction-item",
    "upgrade-item",
)

def parse_library_objects(stream, index, result):

    object_count = stream.count32()
    verbose(f"\nlibrary objects: {object_count}")
    objects = []
    for o in range(object_count):
        is_used = stream.bool()
        if is_used:
            verbose(f"\n[{o}] library slot: used")

            # Interesting: Here is a rare redundancy.
            object_prototype_by_byte = read_mapped8(stream, object_prototypes)

            # See _generation_counter_ in parse_blueprint_library for details.
            generation = stream.u32()

            entry = read_entry(stream, index, Index.ITEM)
            if entry.prototype != object_prototype_by_byte:
                raise ParseError(
                    f"mismatch between content-type '{object_prototype_by_byte}'"
                    f" and actual content item {entry.prototype}")

            handler = object_handlers.get(entry.prototype, None)
            if not handler:
                raise ParseError(f"no handler for {entry.prototype}/{entry.name} ({entry.id:#x})")

            handler_result = handler(stream, index)
            handler_result["_generation_"] = generation
            objects.append(handler_result)
        else:
            verbose(f"\n[{o}] library slot: free")
            objects .append(None)

    result["blueprints"] = objects


def parse_icons(stream, index, result):
    icons = []
    icon_count = stream.count8()
    if not icon_count:
        return
    debug(f"icons: {icon_count}")
    for i in range(icon_count):
        icon = read_signal(stream, index)
        if icon:
            debug(f"    [{i}] '{icon['type']}' / '{icon['name']}'")
            icons.append(icon)
        else:
            debug(f"    [{i}] (none)")
            icons.append(None)
    if icons:
        result["icons"] = icons


def parse_snap_to_grid(stream, result):
    snap_to_grid = stream.bool()
    if snap_to_grid:
        x = stream.u32()
        y = stream.u32()
        result["snap-to-grid"] = {
            "x": x,
            "y": y
        }

        absolute_snapping = stream.bool()
        if absolute_snapping:
            result["absolute-snapping"] = absolute_snapping

def parse_entities(stream, index, result):
    entities = result["entities"] = []

    entity_count = stream.count32()
    debug(f"entities: {entity_count}")
    for e in range(entity_count):
        file_position = stream.tell()

        # type/name
        entry = read_entry(stream, index, Index.ENTITY)

        # position

        # maybe helpfull: https://wiki.factorio.com/Data_types
        # maybe helpfull: https://wiki.factorio.com/Types/Position
        offset_x = stream.s16()     # lookahead
        if offset_x == 0x7fff:
            position = {
                "x": stream.s32() / 256,
                "y": stream.s32() / 256
            }
        else:
            offset_y = stream.s16()
            if entities:
                last_position = entities[-1]["position"]
                position = {
                    "x": last_position["x"] + offset_x / 256,
                    "y": last_position["y"] + offset_y / 256
                }
            else:
                position = {
                    "x": offset_x / 256,
                    "y": offset_y / 256
                }

        # debug output
        debug(f"    [{len(entities)}] @{file_position:#x} - "
            f"x: {position['x']}, y: {position['y']}, "
            f"'{entry.prototype}/{entry.name}'")

        # attach entity
        entity = {
            "name": entry.name,
            "position": position,
        }
        entities.append(entity)

        # Strange: What is this?
        read_unknown(stream, 0x20)

        # parse entity details
        handler = entity_handlers.get(entry.prototype, None)
        if not handler:
            raise ParseError(f"no entity handler for {entry.prototype}/{entry.name} ({entry.id:#x})")
        handler(stream, index, entity)
    
    if not entities:
        del result["entities"]


def parse_schedules(stream, index, result):
    schedules_count = stream.count8()
    schedules = []
    for sc in range(schedules_count):
        schedule = {
            "schedule": []
        }

        locomotives = schedule["locomotives"] = []
        locomotive_count = stream.count8()
        for lo in range(locomotive_count):
            locomotive_id = stream.u32()
            locomotives.append(locomotive_id)

        station_count = stream.count8()
        for st in range(station_count):
            station = {
                "station": stream.string(),
                "wait_conditions": [],
            }

            wait_condition_count = stream.u32()
            for wc in range(wait_condition_count):
                wait_condition = {}

                wait_condition_types = (
                    "time",
                    "full",
                    "empty",
                    "item_count",
                    "circuit",
                    "inactivity",
                    None, # what is type 6?
                    "fluid_count",
                    "passenger_present",
                    "passenger_not_present",
                )
                wait_condition["type"] = read_mapped8(stream, wait_condition_types)

                wait_condition["compare_type"] = read_mapped8(stream, ("and", "or"))

                ticks = stream.u16()
                if ticks:
                    # TODO: export features "ticks: 0" for "time" and "inactivity"
                    wait_condition["ticks"] = ticks

                read_unknown(stream, 0x00, 0x00)

                condition = read_condition(stream, index)
                if condition:
                    wait_condition["condition"] = condition

                station["wait_conditions"].append(wait_condition)

            read_unknown(stream)

            schedule["schedule"].append(station)

        schedules.append(schedule)

    if schedules:
        result["schedules"] = schedules


def parse_tiles(stream, index, result):
    tiles = []
    tile_count = stream.count32()
    debug(f"tiles: {tile_count}")
    for t in range(tile_count):
        tiles.append({
            "position": {
                "x": stream.s32(),
                "y": stream.s32()
            },
            "name": read_name(stream, index, Index.TILE)
        })

    if tiles:
        result["tiles"] = tiles


################################################################
#
# library -- primary objects

def parse_blueprint_library(stream: PrimitiveStream):
    result = {}

    parse_version(stream, result)

    read_unknown(stream)

    parse_migrations(stream, result)

    global_index = parse_index(stream, result)

    read_unknown(stream, 0x00, 0x00)

    # Adding a blueprint to the library increments the counter, deleting and moving does not.
    # When a new blueprint is added to the library this global counter is copied to the new
    # blueprint and incremened after that. This happens for each new blueprint, not per save.
    generation_counter = stream.u32()
    debug(f"generation counter: {generation_counter} ({generation_counter:#x})")
    result["_generation_counter_"] = generation_counter

    # unix timestamp
    timestamp = stream.u32()    # u32/s32?
    timestring = time.strftime("%FT%T%z", time.localtime(timestamp)) # localtime/gmtime?
    # FIXME: use datetime.fromtimestamp(timestamp, timezone.utc) or something like that
    debug(f"timestamp: {timestring}")
    result["_save_timestamp_"] = timestring

    read_unknown(stream, 0x01)

    parse_library_objects(stream, global_index, result)

    return result


def parse_blueprint(stream: PrimitiveStream, index):
    result = {
        "item": "blueprint",
    }

    file_position = stream.tell()

    label = result["label"] = stream.string()
    verbose(f"blueprint '{label}' (@{file_position:#x})")

    read_unknown(stream, 0x00, 0x00)

    # might be "flexible size" marker for $content_size. But since the
    # "migrations" section for 1.0.0.0 is already 347 bytes there is no
    # way to check that.
    read_unknown(stream, 0xff)
    # Interesting: A rare redundancy. Could be used to fast skimming
    # the library. Reasons: a) Speed, b) unparsable content due to mods/versions.
    content_size = stream.u32()
    content_start = stream.tell()

    parse_version(stream, result)

    read_unknown(stream)

    parse_migrations(stream, result)

    result["description"] = stream.string()

    parse_snap_to_grid(stream, result)

    parse_entities(stream, index, result)

    parse_schedules(stream, index, result)

    parse_tiles(stream, index, result)

    read_unknown(stream)

    parse_icons(stream, index, result)

    content_end = stream.tell()
    parsed_size = content_end - content_start
    if parsed_size != content_size:
        raise AssertionError(f"mismatch between declared blueprint size ({content_size})"
            f" and parsed size ({parsed_size})")

    return result


def parse_blueprint_book(stream: PrimitiveStream, index):
    result = {
        "item": "blueprint-book",
    }

    file_position = stream.tell()

    label = result["label"] = stream.string()
    verbose(f"blueprint-book '{label}' (@{file_position:#x})")

    result["description"] = stream.string()

    read_unknown(stream)

    parse_icons(stream, index, result)

    parse_library_objects(stream, index, result)

    active_index = stream.u8()
    if active_index:
        result["active_index"] = active_index

    read_unknown(stream)

    verbose(f"end of book '{label}' (@{stream.tell():#x})")

    return result


def parse_deconstruction_item(stream: PrimitiveStream, index):
    def read_filter(section_name, type):
        filters = []
        filter_count = stream.u8()
        debug(f"{section_name.replace('_', '-')}: {filter_count}")
        for e in range(filter_count):
            name = read_name(stream, index, type)
            filters.append(name)
        result["settings"][section_name] = filters

    result = {
        "item": "deconstruction-planner",
        "settings": {},
    }

    file_position = stream.tell()

    result["label"] = stream.string()
    result["settings"]["description"] = stream.string()

    verbose(f"deconstruction-item '{result['label']}' (@{file_position:#x})")

    read_unknown(stream)

    parse_icons(stream, index, result)

    entity_filter_mode = stream.u8()
    if entity_filter_mode:
        result["settings"]["entity_filter_mode"] = entity_filter_mode

    read_unknown(stream)

    read_filter("entity_filters", Index.ENTITY)

    trees_and_rocks_only = stream.bool()
    if trees_and_rocks_only:
        result["settings"]["trees_and_rocks_only"] = True

    tile_filter_mode = stream.u8()
    if tile_filter_mode:
        result["settings"]["tile_filter_mode"] = tile_filter_mode

    tile_selection_mode = stream.u8()
    if tile_selection_mode:
        result["settings"]["tile_selection_mode"] = tile_selection_mode

    read_unknown(stream)

    read_filter("tile_filters", Index.TILE)

    return result


def parse_upgrade_item(stream: PrimitiveStream, index):
    result = {
        "item": "upgrade-planner",
        "settings": {}
    }

    file_position = stream.tell()

    result["label"] = stream.string()
    result["settings"]["description"] = stream.string()

    verbose(f"upgrade-item '{result['label']}' (@{file_position:#x})")

    read_unknown(stream)

    parse_icons(stream, index, result)

    read_unknown(stream)

    def reader():
        type = read_mapped8(stream, (Index.ENTITY, Index.ITEM))
        name = read_name(stream, index, type)
        if name:
            return {
                "type": type.value,
                "name": name
            }
        else:
            return None

    mappers = []
    mapper_count = stream.count8()
    for m in range(mapper_count):
        # see read_signal but the types are different
        _from = reader()
        _to = reader()
        if _from or _to:
            mappers.append({
                "from": _from,
                "to": _to
            })
        else:
            mappers.append(None)

    result["settings"]["mappers"] = mappers
    return result


object_handlers = {
    "blueprint": parse_blueprint,
    "blueprint-book": parse_blueprint_book,
    "deconstruction-item": parse_deconstruction_item,
    "upgrade-item": parse_upgrade_item,
}


################################################################
#
# main

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--verbose", action="store_true", dest="v",
        help="verbose output on STDERR")
    parser.add_argument("-d", "--debug", action="store_true", dest="d",
        help="debug output on STDERR")
    parser.add_argument("-x", "--extended", action="store_true", dest="x",
        help="extended output: add voluminous stuff found .dat but not used in .export"
        " Currently:\n - migrations\n - prototype index")
    parser.add_argument("filename", nargs="?", default="blueprint-storage.dat")
    opt = parser.parse_args()

    verbose(f"file: {opt.filename}")
    with open(opt.filename, "rb") as f:
        library = parse_blueprint_library(PrimitiveStream(f))
        print(json.dumps(library, indent=4, sort_keys=True, ensure_ascii=False))
